---
title: 'Networks: Complementary and Nested Methods'
date: '2017-11-06'
slug: '/posts/2017/11/networks/'
tags: ""
reading_time: true  # Show estimated reading time?
commentable: true  # Allow visitors to comment? Supported by the Page, Post, and Docs content types.
share: false
---
<p>
Network modelling, in the form of merely linking together actors, points, nodes, etc., based on a particular type of connection, is something that could have and had been done before the introduction of digital technologies. We produce them in order to see what connections we can make between different concepts, historical figures, events, etc. Concept maps, and merely drawing out small network models showing connections within a social group was possible and has been done before now, we could measure centrality by counting edge connections to each node. Digital methods merely allow us to jack up the scope of how many different nodes we are bringing into the model, how many data points we can examine at once and consider at any one given time. They also allow us to weight the edge connections differently which adds some further specificity to our models, allowing us to numerically determine the strength of different connections, providing us with a grounds upon which to determine which connections are more important than others. Again, this method was possible beforehand; we could count connections, and we could make our own typologies and determinations of what connections were more important than others.
</p>
<br/>
<p>
What digital technologies bring to the table is simply the ability to quantify the strength of these connection, to create a more rigorous and structural method to carry out centrality measurements across a larger swath of nodes. It allows us to see a more specified and fleshed out picture of network relations than we could have before the advance of digital technologies, the method of network analysis itself, considered separate from a reliance on computational technologies, useful beforehand, and modified and juiced up after it.
</p>
<br/>
<p>
What struck me most about reading Scott Weingart’s <em>Demystifying Networks</em> was not necessarily the novelty that network modelling and analysis brings to the table, but the way that it complements the last few techniques that we have studied. Text-based computational methods, used to identify specific relationships within a text, as well as delineate when and where certain terms appear, seem to form a pre-condition for using network analysis on large datasets. We need the text-analysis algorithms and techniques to sort through vast amounts of data, to collect the terms and relationships we need in order to create large scale network models. The same could be said about the geographic and spatial methods we covered last week, we need the first stage of data mining algorithms in order to operationalize this data to make maps and geographic representations of the data.
</p>
<br/>
<p>
What is interesting at this stage in our survey of digital history methods is the complementarity of these techniques, of the nested nature they assume once we jump beyond the bedrock of digital methods: the data mining text algorithm. Even though the methods of mapping and network analysis existed in some form before the digital turn, their current forms are only possible with the advent of digital technologies. At the end of the day however, it is not as though these techniques supplant traditional historical methods, or displace the supremacy of any one type of epistemology applied to history or humanities research. On the contrary, what they allow the researcher to do is to introduce a prism by which the original subject matter, its murky content, is refracted through a multiplicity of lens and sources, each acting as a unique window through which to view the phenomenon in question, each unique in its own manner but also incomplete. The phenomenon itself remains inexhaustible, each method only capturing but a fragmentary glimpse of the whole, laden with their own particular limitations.
</p>
<br/>
<p>
What strikes me about the complementarity and nested nature of these digital methods is the fact that they almost inherently take this epistemological stance, the one that I have sketched above, explicitly in their constructs and outputs. The use of the different digital tools, such as mapping tech and network analysis, recognize themselves as merely shifting the lens and position of the observer of the phenomenon. No single network, or map, hopes to exhaust the phenomenon in general, but to produce different new data points and perspectives. When these perspectives are brought together in the synthetic action of knowledge production, it is up to the researcher to connect these representations together into a synthetic whole, into a product of knowledge. This qualification of these techniques as tools rather than as central aspects of knowledge realizes and attempts to actualize this epistemological metaphor of the prism.
</p>
<br/>
<p>
When Weingart discusses the limitations of the technology, of network analysis, he discusses how this is both a blessing and a curse; it forces us to acknowledge the incompleteness of the representations we create, that we cannot go beyond bi-modal networks, and that even so most of the algorithms available for centrality measurements only work on singular networks of one type of node. Thus we are limited by the tools we use, and thus we need to limit the types of conclusions we draw from the visualizations and findings these tools produce. It necessitates a different understanding of data, or knowledge, and of proof. Instead of these representations created by these methods serving as objective and infallible units of truth, they act instead as almost arcane visions of what could be, of experiments in connecting the dots, or multiplying the perspectives of a phenomenon available for its understanding. Thus, also due to the limitations of any given one of these digital tools, we are compelled to make more and more models and representations to generate new research questions, new hypotheses, that can then drive our act of synthetic knowledge production.
</p>
<br/>
<p>
This is highlighted in Winterer’s piece <em>Where is America in the Republic of Letters?</em> as she shows the variety of ways to consider how involved America was in the European Republic of Letters, a question that really can only ever remain fuzzy. If network analysis only allows us to compellingly consider one type of stuff, or even two, that limits the type of questions we can ask. Then again, it also forces us to ask the same question in a multitude of ways, it forces us to continually unbound and rebound, combine and recombine elements in different ways. This is especially the case when we have to consider which institutions and individuals we should be linking, how we should weight different connections, what are we defining as core and periphery, how is this determined or questioned by which tool we are using. We need to embrace the fuzziness, not run from it as it is the absolute of observation and knowledge. Each method has its own fuzziness implied, but the more methods we employ the more the overall fuzziness (or in statistical language error) is checked and controlled for.
</p>
<br/>
<p>
This also speaks to the complementarity of mapping technology and network analysis. Questions that can be answered or asked by one method can necessarily be answered by the other; it seems a logical step to want to go from a  map of a particular phenomenon considered spatially, to a “map”, a network, of the actors and institutions involved, considering the different factors that impinge and shape these relationships, and vice versa. What digital tools allow us to do is proliferate the number of perspectives we bring to the table, that also bring with it explicit statements of the limitations of each new refraction, always pointing to the fact that we need to consider the phenomenon from multiple perspectives, that text algorithms tell us one thing, but then another when we use them to produce maps and network models, etc. It seems that by demarcating which methods can be used in a complementary fashion, we could expand the scope of our observations, which always generates with it a more fertile ground for synthetic knowledge production. We should not avoid these methods in fear that they will supplant other forms of inquiry, but embrace them go through them, in order to actualize the prism of knowledge, to make it refract all the colors of the rainbow.
</p>
